{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "import numpy as np\n",
    "import pygame\n",
    "import random\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cria o jogo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "MAX_VEL_X = 5.0\n",
    "MAX_VEL_Y = 5.0\n",
    "\n",
    "class LunarLandingEnv(gym.Env):\n",
    "    metadata = {'render_modes': ['human'], 'render_fps': 60}\n",
    "\n",
    "    def __init__(self):\n",
    "        super(LunarLandingEnv, self).__init__()\n",
    "\n",
    "        # Define action and observation space\n",
    "        # Actions: 0 - Do nothing, 1 - Thrust Up, 2 - Thrust Left, 3 - Thrust Right\n",
    "        self.action_space = spaces.Discrete(4)\n",
    "\n",
    "        # Observations: x, y, velocity_x, velocity_y, fuel, landing_center_norm\n",
    "        low = np.array([-1, -1, -1, -1, 0, -1], dtype=np.float32)\n",
    "        high = np.array([1, 1, 1, 1, 1, 1], dtype=np.float32)\n",
    "        self.observation_space = spaces.Box(low, high, dtype=np.float32)\n",
    "\n",
    "        # Game parameters\n",
    "        self.gravity = 0.05\n",
    "        self.thrust_vertical = 0.1\n",
    "        self.thrust_horizontal = 0.05\n",
    "        self.max_fuel = 1000  # Increased fuel\n",
    "\n",
    "        # Pygame initialization\n",
    "        self.screen_width = 800\n",
    "        self.screen_height = 600\n",
    "        self.screen = None\n",
    "        self.clock = None\n",
    "        self.is_open = True\n",
    "\n",
    "        # Game outcome\n",
    "        self.last_outcome = None  # Will be 'victory' or 'defeat' when the game ends\n",
    "\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        super().reset(seed=seed)\n",
    "        self.x = self.screen_width / 2  # Start at the center\n",
    "        self.y = 50\n",
    "        self.vel_x = 0.0\n",
    "        self.vel_y = 0.0\n",
    "        self.fuel = self.max_fuel\n",
    "        self.landing_zone = self._choose_landing_zone()\n",
    "        self.current_step = 0  # Step counter\n",
    "        self.max_steps = 1000  # Max steps per episode\n",
    "        self.last_outcome = None  # Reset outcome\n",
    "        return self._get_obs(), {}\n",
    "\n",
    "    def step(self, action):\n",
    "        # Apply action\n",
    "        if action == 1 and self.fuel > 0:  # Thrust Up\n",
    "            self.vel_y -= self.thrust_vertical\n",
    "            self.fuel -= 1\n",
    "        elif action == 2 and self.fuel > 0:  # Thrust Left\n",
    "            self.vel_x -= self.thrust_horizontal\n",
    "            self.fuel -= 1\n",
    "        elif action == 3 and self.fuel > 0:  # Thrust Right\n",
    "            self.vel_x += self.thrust_horizontal\n",
    "            self.fuel -= 1\n",
    "\n",
    "        # Update physics\n",
    "        self.vel_y += self.gravity\n",
    "        self.y += self.vel_y\n",
    "        self.x += self.vel_x\n",
    "\n",
    "        # Impose horizontal limits\n",
    "        self.x = max(20, min(self.x, 780))\n",
    "\n",
    "        # Increment step counter\n",
    "        self.current_step += 1\n",
    "\n",
    "        # Initialize reward and constants\n",
    "        reward = 0.0\n",
    "        k_y = 5  # Weight for vertical velocity adjustment\n",
    "        k_x = 4   # Weight for horizontal velocity adjustment\n",
    "        k_dir = 3  # Weight to penalize wrong direction\n",
    "        k_dist = 1  # Weight for distance from center\n",
    "\n",
    "        # Calculate landing zone center\n",
    "        landing_center = (self.landing_zone[0] + self.landing_zone[1]) / 2\n",
    "        distance_to_center_x = self.x - landing_center\n",
    "\n",
    "        # Reward for low and positive Y velocity\n",
    "        if 0.5 <= self.vel_y <= 1:\n",
    "            reward += k_y  # Max reward for ideal velocity\n",
    "        else:\n",
    "            reward -= k_y * abs(self.vel_y - 0.75)  # Penalty proportional to deviation from 0.75\n",
    "\n",
    "        if self.x < landing_center:  # Lander is to the left\n",
    "            if self.vel_x < 0.4:\n",
    "                if action == 3:  # Pushing to the right\n",
    "                    reward += k_x\n",
    "                elif action == 2:  # Pushing to the left\n",
    "                    reward -= k_dir\n",
    "\n",
    "        elif self.x > landing_center:  # Lander is to the right\n",
    "            if self.vel_x > -0.4:\n",
    "                if action == 2:  # Pushing to the left\n",
    "                    reward += k_x\n",
    "                elif action == 3:  # Pushing to the right\n",
    "                    reward -= k_dir\n",
    "\n",
    "        # Normalize reward between -10 and 10\n",
    "        reward = max(-10, min(10, reward))\n",
    "\n",
    "        # Check for termination\n",
    "        terminated = False\n",
    "        if self.y >= 530:  # Lander has reached the platform height\n",
    "            self.y = 530  # Adjust position to exactly on platform\n",
    "            # Determine if landing is successful\n",
    "            landing_velocity_threshold = 0.8  # units\n",
    "            if self.x > self.landing_zone[0] and self.x < self.landing_zone[1] and abs(self.vel_y) <= landing_velocity_threshold:\n",
    "                # Successful landing\n",
    "                self.last_outcome = 'victory'\n",
    "            else:\n",
    "                # Unsuccessful landing\n",
    "                self.last_outcome = 'defeat'\n",
    "            self.vel_y = 0  # Stop vertical movement\n",
    "            self.vel_x = 0  # Stop horizontal movement\n",
    "\n",
    "            terminated = True\n",
    "\n",
    "        elif self.current_step >= self.max_steps:\n",
    "            terminated = True\n",
    "            self.last_outcome = 'defeat'\n",
    "        elif self.y > self.screen_height or self.x <= 20 or self.x >= 780:\n",
    "            terminated = True\n",
    "            reward = -10  # Max penalty for going out of bounds\n",
    "            self.last_outcome = 'defeat'\n",
    "\n",
    "        # Return observations, reward, and episode info\n",
    "        return self._get_obs(), reward, terminated, False, {}\n",
    "\n",
    "    def render(self):\n",
    "        if self.screen is None:\n",
    "            pygame.init()\n",
    "            pygame.display.init()\n",
    "            self.screen = pygame.display.set_mode(\n",
    "                (self.screen_width, self.screen_height)\n",
    "            )\n",
    "        if self.clock is None:\n",
    "            self.clock = pygame.time.Clock()\n",
    "\n",
    "        if self.last_outcome is None:\n",
    "            # Normal game rendering\n",
    "            self.screen.fill((0, 0, 0))  # Clear screen\n",
    "\n",
    "            # Draw game elements\n",
    "            self._draw_stars()\n",
    "            self._draw_terrain()\n",
    "            self._draw_lander()\n",
    "\n",
    "            # Show game state information\n",
    "            landing_center = (self.landing_zone[0] + self.landing_zone[1]) / 2\n",
    "            distance_to_center = self.x - landing_center\n",
    "\n",
    "            # Display rocket coordinates and state\n",
    "            font = pygame.font.Font(None, 36)\n",
    "            info_text = [\n",
    "                f\"Rocket X: {self.x:.2f}\",\n",
    "                f\"Rocket Y: {self.y:.2f}\",\n",
    "                f\"Distance to Center: {distance_to_center:.2f}\",\n",
    "                f\"Velocity X: {self.vel_x:.2f}\",\n",
    "                f\"Velocity Y: {self.vel_y:.2f}\",\n",
    "                f\"Fuel: {self.fuel}\",\n",
    "                f\"Landing Center X: {landing_center:.2f}\",\n",
    "            ]\n",
    "            for i, text in enumerate(info_text):\n",
    "                surface = font.render(text, True, (255, 255, 255))\n",
    "                self.screen.blit(surface, (10, 10 + i * 30))\n",
    "\n",
    "            # Visual marker for landing platform center\n",
    "            pygame.draw.circle(\n",
    "                self.screen, (0, 255, 0), (int(landing_center), 550), 5\n",
    "            )\n",
    "\n",
    "            # Display rocket's current coordinates next to it\n",
    "            coord_text = f\"({int(self.x)}, {int(self.y)})\"\n",
    "            coord_surface = font.render(coord_text, True, (255, 255, 255))\n",
    "            self.screen.blit(coord_surface, (int(self.x) + 20, int(self.y) - 40))\n",
    "\n",
    "            # Update display\n",
    "            pygame.display.flip()\n",
    "            self.clock.tick(self.metadata[\"render_fps\"])\n",
    "        else:\n",
    "            # Draw victory or defeat screen\n",
    "            self._draw_end_screen()\n",
    "\n",
    "    def _draw_end_screen(self):\n",
    "        # Clear screen\n",
    "        self.screen.fill((0, 0, 0))\n",
    "\n",
    "        # Victory or defeat text\n",
    "        font = pygame.font.Font(None, 74)\n",
    "        if self.last_outcome == 'victory':\n",
    "            text = font.render(\"YOU WIN!\", True, (0, 255, 0))\n",
    "        else:\n",
    "            text = font.render(\"GAME OVER\", True, (255, 0, 0))\n",
    "        text_rect = text.get_rect(center=(self.screen_width // 2, self.screen_height // 2))\n",
    "        self.screen.blit(text, text_rect)\n",
    "\n",
    "        # Update display\n",
    "        pygame.display.flip()\n",
    "\n",
    "    def close(self):\n",
    "        if self.screen is not None:\n",
    "            pygame.display.quit()\n",
    "            pygame.quit()\n",
    "            self.is_open = False\n",
    "\n",
    "    # Helper methods\n",
    "    def _choose_landing_zone(self):\n",
    "        start = random.randint(100, 600)\n",
    "        width = random.randint(50, 150)\n",
    "        end = start + width\n",
    "        return (start, end)\n",
    "\n",
    "    def _get_obs(self):\n",
    "        x_norm = (self.x - self.screen_width / 2) / (self.screen_width / 2)\n",
    "        y_norm = (self.y - self.screen_height / 2) / (self.screen_height / 2)\n",
    "        vel_x_norm = self.vel_x / MAX_VEL_X\n",
    "        vel_y_norm = self.vel_y / MAX_VEL_Y\n",
    "        fuel_norm = self.fuel / self.max_fuel\n",
    "        landing_center_norm = (self.landing_zone[0] + self.landing_zone[1]) / 2 / self.screen_width\n",
    "        return np.array(\n",
    "            [x_norm, y_norm, vel_x_norm, vel_y_norm, fuel_norm, landing_center_norm],\n",
    "            dtype=np.float32,\n",
    "        )\n",
    "\n",
    "    def _draw_stars(self):\n",
    "        # Draw static stars\n",
    "        if not hasattr(self, \"stars\"):\n",
    "            self.stars = [\n",
    "                (random.randint(0, 800), random.randint(0, 600)) for _ in range(50)\n",
    "            ]\n",
    "        for star in self.stars:\n",
    "            pygame.draw.circle(self.screen, (255, 255, 255), star, 2)\n",
    "\n",
    "    def _draw_terrain(self):\n",
    "        # Draw terrain and landing zone\n",
    "        pygame.draw.polygon(\n",
    "            self.screen,\n",
    "            (100, 100, 100),\n",
    "            [\n",
    "                (0, 550),\n",
    "                (200, 450),\n",
    "                (400, 500),\n",
    "                (600, 450),\n",
    "                (800, 550),\n",
    "                (800, 600),\n",
    "                (0, 600),\n",
    "            ],\n",
    "        )\n",
    "        # Draw landing zone\n",
    "        start, end = self.landing_zone\n",
    "        pygame.draw.rect(\n",
    "            self.screen, (150, 150, 150), (start, 550, end - start, 50)\n",
    "        )\n",
    "        # Flags\n",
    "        pygame.draw.line(self.screen, (255, 255, 255), (start, 550), (start, 520), 2)\n",
    "        pygame.draw.polygon(\n",
    "            self.screen,\n",
    "            (255, 255, 0),\n",
    "            [(start, 520), (start + 15, 527), (start, 534)],\n",
    "        )\n",
    "        pygame.draw.line(self.screen, (255, 255, 255), (end, 550), (end, 520), 2)\n",
    "        pygame.draw.polygon(\n",
    "            self.screen,\n",
    "            (255, 255, 0),\n",
    "            [(end, 520), (end - 15, 527), (end, 534)],\n",
    "        )\n",
    "\n",
    "    def _draw_lander(self):\n",
    "        x = int(self.x)\n",
    "        y = int(self.y)\n",
    "\n",
    "        # Draw the lander\n",
    "        pygame.draw.rect(\n",
    "            self.screen, (200, 200, 200), (x - 10, y - 30, 20, 60)\n",
    "        )  # Main body\n",
    "        pygame.draw.polygon(\n",
    "            self.screen,\n",
    "            (150, 150, 150),\n",
    "            [(x - 10, y + 20), (x - 20, y + 30), (x - 10, y + 30)],\n",
    "        )  # Left wing\n",
    "        pygame.draw.polygon(\n",
    "            self.screen,\n",
    "            (150, 150, 150),\n",
    "            [(x + 10, y + 20), (x + 20, y + 30), (x + 10, y + 30)],\n",
    "        )  # Right wing\n",
    "        pygame.draw.polygon(\n",
    "            self.screen,\n",
    "            (255, 0, 0),\n",
    "            [(x, y - 40), (x - 10, y - 30), (x + 10, y - 30)],\n",
    "        )  # Top cone\n",
    "\n",
    "        # Draw fuel level indicator\n",
    "        fuel_percentage = self.fuel / self.max_fuel\n",
    "        fuel_bar_height = 50\n",
    "        fuel_bar_width = 10\n",
    "        pygame.draw.rect(\n",
    "            self.screen,\n",
    "            (255, 255, 255),\n",
    "            (x - 25, y - 30, fuel_bar_width, fuel_bar_height),\n",
    "            1,\n",
    "        )  # Fuel bar border\n",
    "        pygame.draw.rect(\n",
    "            self.screen,\n",
    "            (0, 255, 0),\n",
    "            (\n",
    "                x - 25,\n",
    "                y - 30 + fuel_bar_height * (1 - fuel_percentage),\n",
    "                fuel_bar_width,\n",
    "                fuel_bar_height * fuel_percentage,\n",
    "            ),\n",
    "        )  # Fuel bar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Para treinar o bot (pode demorar dependendo do número de iterações definido em total_timesteps):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Logging to ./ppo_lunar_landing_tensorboard/PPO_58\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 9771 |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 0    |\n",
      "|    total_timesteps | 8192 |\n",
      "-----------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 4075        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 4           |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008953445 |\n",
      "|    clip_fraction        | 0.0852      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.38       |\n",
      "|    explained_variance   | 0.00252     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.83e+03    |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.00239    |\n",
      "|    value_loss           | 1.05e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 3431       |\n",
      "|    iterations           | 3          |\n",
      "|    time_elapsed         | 7          |\n",
      "|    total_timesteps      | 24576      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01339993 |\n",
      "|    clip_fraction        | 0.176      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.36      |\n",
      "|    explained_variance   | 5.92e-05   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 4.16e+03   |\n",
      "|    n_updates            | 20         |\n",
      "|    policy_gradient_loss | -0.00636   |\n",
      "|    value_loss           | 9.4e+03    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 3184        |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 10          |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012818901 |\n",
      "|    clip_fraction        | 0.0837      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.32       |\n",
      "|    explained_variance   | -1e-05      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.05e+03    |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0031     |\n",
      "|    value_loss           | 7.58e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 3013         |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 13           |\n",
      "|    total_timesteps      | 40960        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066098785 |\n",
      "|    clip_fraction        | 0.153        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.26        |\n",
      "|    explained_variance   | -7.15e-07    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.69e+03     |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.00465     |\n",
      "|    value_loss           | 5e+03        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2925        |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 16          |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009933866 |\n",
      "|    clip_fraction        | 0.0113      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.25       |\n",
      "|    explained_variance   | 0.265       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.17e+03    |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.00314    |\n",
      "|    value_loss           | 2.74e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2874        |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 19          |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010429132 |\n",
      "|    clip_fraction        | 0.0715      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.27       |\n",
      "|    explained_variance   | 0.0334      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.26e+03    |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.00682    |\n",
      "|    value_loss           | 2.87e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2845         |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 23           |\n",
      "|    total_timesteps      | 65536        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0086407205 |\n",
      "|    clip_fraction        | 0.0514       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.29        |\n",
      "|    explained_variance   | 0.155        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 859          |\n",
      "|    n_updates            | 70           |\n",
      "|    policy_gradient_loss | -0.00717     |\n",
      "|    value_loss           | 2.45e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2811        |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 26          |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012190408 |\n",
      "|    clip_fraction        | 0.0805      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.15       |\n",
      "|    explained_variance   | 0.409       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 827         |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.016      |\n",
      "|    value_loss           | 1.92e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2787        |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 29          |\n",
      "|    total_timesteps      | 81920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013566297 |\n",
      "|    clip_fraction        | 0.0647      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.3        |\n",
      "|    explained_variance   | 0.138       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 345         |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0128     |\n",
      "|    value_loss           | 1.4e+03     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2777        |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 32          |\n",
      "|    total_timesteps      | 90112       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012603519 |\n",
      "|    clip_fraction        | 0.0736      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.14       |\n",
      "|    explained_variance   | 0.487       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 690         |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0144     |\n",
      "|    value_loss           | 1.49e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2767        |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 35          |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015751991 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.31       |\n",
      "|    explained_variance   | 0.475       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 669         |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0229     |\n",
      "|    value_loss           | 1.56e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 2748       |\n",
      "|    iterations           | 13         |\n",
      "|    time_elapsed         | 38         |\n",
      "|    total_timesteps      | 106496     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01616631 |\n",
      "|    clip_fraction        | 0.194      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.12      |\n",
      "|    explained_variance   | 0.451      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 945        |\n",
      "|    n_updates            | 120        |\n",
      "|    policy_gradient_loss | -0.0292    |\n",
      "|    value_loss           | 1.68e+03   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2742        |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 41          |\n",
      "|    total_timesteps      | 114688      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009200164 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.29       |\n",
      "|    explained_variance   | 0.411       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 474         |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0194     |\n",
      "|    value_loss           | 1.52e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2737        |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 44          |\n",
      "|    total_timesteps      | 122880      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008076276 |\n",
      "|    clip_fraction        | 0.0378      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.22       |\n",
      "|    explained_variance   | 0.372       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 486         |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.013      |\n",
      "|    value_loss           | 1.23e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2727        |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 48          |\n",
      "|    total_timesteps      | 131072      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008963152 |\n",
      "|    clip_fraction        | 0.0855      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.23       |\n",
      "|    explained_variance   | 0.519       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 780         |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.0117     |\n",
      "|    value_loss           | 1.14e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2722        |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 51          |\n",
      "|    total_timesteps      | 139264      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008556497 |\n",
      "|    clip_fraction        | 0.0821      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.22       |\n",
      "|    explained_variance   | 0.741       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 534         |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0089     |\n",
      "|    value_loss           | 846         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2720         |\n",
      "|    iterations           | 18           |\n",
      "|    time_elapsed         | 54           |\n",
      "|    total_timesteps      | 147456       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075325505 |\n",
      "|    clip_fraction        | 0.0778       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.22        |\n",
      "|    explained_variance   | 0.888        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 130          |\n",
      "|    n_updates            | 170          |\n",
      "|    policy_gradient_loss | -0.00837     |\n",
      "|    value_loss           | 690          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2710        |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 57          |\n",
      "|    total_timesteps      | 155648      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009092132 |\n",
      "|    clip_fraction        | 0.0909      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.16       |\n",
      "|    explained_variance   | 0.908       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 106         |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.00456    |\n",
      "|    value_loss           | 577         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2707        |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 60          |\n",
      "|    total_timesteps      | 163840      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008075493 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.18       |\n",
      "|    explained_variance   | 0.943       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 64.3        |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.00855    |\n",
      "|    value_loss           | 425         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2706        |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 63          |\n",
      "|    total_timesteps      | 172032      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008684186 |\n",
      "|    clip_fraction        | 0.0885      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.22       |\n",
      "|    explained_variance   | 0.972       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 52.7        |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.00905    |\n",
      "|    value_loss           | 286         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2701         |\n",
      "|    iterations           | 22           |\n",
      "|    time_elapsed         | 66           |\n",
      "|    total_timesteps      | 180224       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055300114 |\n",
      "|    clip_fraction        | 0.0512       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.19        |\n",
      "|    explained_variance   | 0.973        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 39.5         |\n",
      "|    n_updates            | 210          |\n",
      "|    policy_gradient_loss | -0.0018      |\n",
      "|    value_loss           | 233          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2692        |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 69          |\n",
      "|    total_timesteps      | 188416      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008070716 |\n",
      "|    clip_fraction        | 0.0902      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.17       |\n",
      "|    explained_variance   | 0.976       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 28.7        |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | -0.00562    |\n",
      "|    value_loss           | 167         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2690         |\n",
      "|    iterations           | 24           |\n",
      "|    time_elapsed         | 73           |\n",
      "|    total_timesteps      | 196608       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060850214 |\n",
      "|    clip_fraction        | 0.0823       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.18        |\n",
      "|    explained_variance   | 0.985        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 19.4         |\n",
      "|    n_updates            | 230          |\n",
      "|    policy_gradient_loss | -0.00276     |\n",
      "|    value_loss           | 102          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2689         |\n",
      "|    iterations           | 25           |\n",
      "|    time_elapsed         | 76           |\n",
      "|    total_timesteps      | 204800       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0079536615 |\n",
      "|    clip_fraction        | 0.111        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.13        |\n",
      "|    explained_variance   | 0.991        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 19.5         |\n",
      "|    n_updates            | 240          |\n",
      "|    policy_gradient_loss | -0.00594     |\n",
      "|    value_loss           | 78.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2684        |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 79          |\n",
      "|    total_timesteps      | 212992      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007910528 |\n",
      "|    clip_fraction        | 0.0793      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.16       |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 15.7        |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.00209    |\n",
      "|    value_loss           | 58.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2684        |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 82          |\n",
      "|    total_timesteps      | 221184      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005855404 |\n",
      "|    clip_fraction        | 0.0574      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.15       |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 11.7        |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.00127    |\n",
      "|    value_loss           | 56.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2683        |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 85          |\n",
      "|    total_timesteps      | 229376      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007412245 |\n",
      "|    clip_fraction        | 0.0914      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.13       |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 15.9        |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.00488    |\n",
      "|    value_loss           | 48          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2680        |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 88          |\n",
      "|    total_timesteps      | 237568      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010282445 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.11       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 16.2        |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.00698    |\n",
      "|    value_loss           | 46.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2678        |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 91          |\n",
      "|    total_timesteps      | 245760      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008201131 |\n",
      "|    clip_fraction        | 0.0952      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.11       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 21.3        |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.004      |\n",
      "|    value_loss           | 43.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2677        |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 94          |\n",
      "|    total_timesteps      | 253952      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012048412 |\n",
      "|    clip_fraction        | 0.165       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.1        |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 27.6        |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.00913    |\n",
      "|    value_loss           | 39.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2677        |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 97          |\n",
      "|    total_timesteps      | 262144      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008222004 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.12       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 31.4        |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.00401    |\n",
      "|    value_loss           | 48.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2674        |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 101         |\n",
      "|    total_timesteps      | 270336      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007495149 |\n",
      "|    clip_fraction        | 0.0929      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.06       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 21.1        |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.00306    |\n",
      "|    value_loss           | 53.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2673        |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 104         |\n",
      "|    total_timesteps      | 278528      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012830748 |\n",
      "|    clip_fraction        | 0.186       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.08       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 20          |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    value_loss           | 41          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2674         |\n",
      "|    iterations           | 35           |\n",
      "|    time_elapsed         | 107          |\n",
      "|    total_timesteps      | 286720       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061417716 |\n",
      "|    clip_fraction        | 0.0987       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.06        |\n",
      "|    explained_variance   | 0.995        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 16           |\n",
      "|    n_updates            | 340          |\n",
      "|    policy_gradient_loss | -0.00154     |\n",
      "|    value_loss           | 50.6         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2670         |\n",
      "|    iterations           | 36           |\n",
      "|    time_elapsed         | 110          |\n",
      "|    total_timesteps      | 294912       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072264145 |\n",
      "|    clip_fraction        | 0.0935       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.04        |\n",
      "|    explained_variance   | 0.996        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 26           |\n",
      "|    n_updates            | 350          |\n",
      "|    policy_gradient_loss | -0.00073     |\n",
      "|    value_loss           | 56           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2669        |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 113         |\n",
      "|    total_timesteps      | 303104      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008190082 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.02       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 19.9        |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.00153    |\n",
      "|    value_loss           | 47.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2669        |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 116         |\n",
      "|    total_timesteps      | 311296      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009122732 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.02       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 20.9        |\n",
      "|    n_updates            | 370         |\n",
      "|    policy_gradient_loss | -0.00482    |\n",
      "|    value_loss           | 48.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2666        |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 119         |\n",
      "|    total_timesteps      | 319488      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009952443 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.985      |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 39.3        |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.00504    |\n",
      "|    value_loss           | 80.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2666        |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 122         |\n",
      "|    total_timesteps      | 327680      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008274133 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.986      |\n",
      "|    explained_variance   | 0.992       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 22.3        |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.0019     |\n",
      "|    value_loss           | 110         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2666        |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 125         |\n",
      "|    total_timesteps      | 335872      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008112324 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.974      |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 27.3        |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.000929   |\n",
      "|    value_loss           | 70.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2665        |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 129         |\n",
      "|    total_timesteps      | 344064      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009546894 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.978      |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 30          |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | 0.00103     |\n",
      "|    value_loss           | 65.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2657        |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 132         |\n",
      "|    total_timesteps      | 352256      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007928412 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.969      |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 30.3        |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.00293    |\n",
      "|    value_loss           | 62.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2656        |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 135         |\n",
      "|    total_timesteps      | 360448      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006887256 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.938      |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 27.6        |\n",
      "|    n_updates            | 430         |\n",
      "|    policy_gradient_loss | -0.00442    |\n",
      "|    value_loss           | 90.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2337        |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 157         |\n",
      "|    total_timesteps      | 368640      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009821052 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.903      |\n",
      "|    explained_variance   | 0.988       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 56.5        |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.00404    |\n",
      "|    value_loss           | 134         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2333        |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 161         |\n",
      "|    total_timesteps      | 376832      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009243898 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.923      |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 28.7        |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.00125    |\n",
      "|    value_loss           | 86.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2333         |\n",
      "|    iterations           | 47           |\n",
      "|    time_elapsed         | 164          |\n",
      "|    total_timesteps      | 385024       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071902485 |\n",
      "|    clip_fraction        | 0.122        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.876       |\n",
      "|    explained_variance   | 0.991        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 44.1         |\n",
      "|    n_updates            | 460          |\n",
      "|    policy_gradient_loss | -0.00347     |\n",
      "|    value_loss           | 121          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2338        |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 168         |\n",
      "|    total_timesteps      | 393216      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008121952 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.907      |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 59          |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.00207    |\n",
      "|    value_loss           | 70.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2342        |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 171         |\n",
      "|    total_timesteps      | 401408      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009026305 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.913      |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 62.4        |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.000613   |\n",
      "|    value_loss           | 73          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2348         |\n",
      "|    iterations           | 50           |\n",
      "|    time_elapsed         | 174          |\n",
      "|    total_timesteps      | 409600       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0079497015 |\n",
      "|    clip_fraction        | 0.0956       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.892       |\n",
      "|    explained_variance   | 0.995        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 22.5         |\n",
      "|    n_updates            | 490          |\n",
      "|    policy_gradient_loss | 0.000533     |\n",
      "|    value_loss           | 72.1         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2353        |\n",
      "|    iterations           | 51          |\n",
      "|    time_elapsed         | 177         |\n",
      "|    total_timesteps      | 417792      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008204039 |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.887      |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 26.5        |\n",
      "|    n_updates            | 500         |\n",
      "|    policy_gradient_loss | -0.00389    |\n",
      "|    value_loss           | 76.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2357        |\n",
      "|    iterations           | 52          |\n",
      "|    time_elapsed         | 180         |\n",
      "|    total_timesteps      | 425984      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009119113 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.892      |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 28.4        |\n",
      "|    n_updates            | 510         |\n",
      "|    policy_gradient_loss | -0.00233    |\n",
      "|    value_loss           | 63.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2362        |\n",
      "|    iterations           | 53          |\n",
      "|    time_elapsed         | 183         |\n",
      "|    total_timesteps      | 434176      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007583554 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.9        |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 24.7        |\n",
      "|    n_updates            | 520         |\n",
      "|    policy_gradient_loss | 0.000183    |\n",
      "|    value_loss           | 54.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2367        |\n",
      "|    iterations           | 54          |\n",
      "|    time_elapsed         | 186         |\n",
      "|    total_timesteps      | 442368      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006995328 |\n",
      "|    clip_fraction        | 0.0874      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.863      |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 20.5        |\n",
      "|    n_updates            | 530         |\n",
      "|    policy_gradient_loss | 0.00147     |\n",
      "|    value_loss           | 70.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2371        |\n",
      "|    iterations           | 55          |\n",
      "|    time_elapsed         | 189         |\n",
      "|    total_timesteps      | 450560      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006854005 |\n",
      "|    clip_fraction        | 0.0969      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.863      |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 32.1        |\n",
      "|    n_updates            | 540         |\n",
      "|    policy_gradient_loss | 0.000206    |\n",
      "|    value_loss           | 64.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2375        |\n",
      "|    iterations           | 56          |\n",
      "|    time_elapsed         | 193         |\n",
      "|    total_timesteps      | 458752      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009331871 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.842      |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 36.1        |\n",
      "|    n_updates            | 550         |\n",
      "|    policy_gradient_loss | -0.00203    |\n",
      "|    value_loss           | 45.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 2380         |\n",
      "|    iterations           | 57           |\n",
      "|    time_elapsed         | 196          |\n",
      "|    total_timesteps      | 466944       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077231666 |\n",
      "|    clip_fraction        | 0.132        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.874       |\n",
      "|    explained_variance   | 0.995        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 35.2         |\n",
      "|    n_updates            | 560          |\n",
      "|    policy_gradient_loss | -0.00179     |\n",
      "|    value_loss           | 63.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2385        |\n",
      "|    iterations           | 58          |\n",
      "|    time_elapsed         | 199         |\n",
      "|    total_timesteps      | 475136      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009099062 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.877      |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 18.4        |\n",
      "|    n_updates            | 570         |\n",
      "|    policy_gradient_loss | 0.00151     |\n",
      "|    value_loss           | 41.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2388        |\n",
      "|    iterations           | 59          |\n",
      "|    time_elapsed         | 202         |\n",
      "|    total_timesteps      | 483328      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006281167 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.851      |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 17.5        |\n",
      "|    n_updates            | 580         |\n",
      "|    policy_gradient_loss | -0.000712   |\n",
      "|    value_loss           | 52.1        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 2392       |\n",
      "|    iterations           | 60         |\n",
      "|    time_elapsed         | 205        |\n",
      "|    total_timesteps      | 491520     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00849239 |\n",
      "|    clip_fraction        | 0.122      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.844     |\n",
      "|    explained_variance   | 0.995      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 32.5       |\n",
      "|    n_updates            | 590        |\n",
      "|    policy_gradient_loss | -0.00157   |\n",
      "|    value_loss           | 58.7       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2396        |\n",
      "|    iterations           | 61          |\n",
      "|    time_elapsed         | 208         |\n",
      "|    total_timesteps      | 499712      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014548812 |\n",
      "|    clip_fraction        | 0.225       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.858      |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 22.3        |\n",
      "|    n_updates            | 600         |\n",
      "|    policy_gradient_loss | -0.00923    |\n",
      "|    value_loss           | 45.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 2399        |\n",
      "|    iterations           | 62          |\n",
      "|    time_elapsed         | 211         |\n",
      "|    total_timesteps      | 507904      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010502629 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.853      |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 18          |\n",
      "|    n_updates            | 610         |\n",
      "|    policy_gradient_loss | -1.88e-05   |\n",
      "|    value_loss           | 46.9        |\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "\n",
    "# Callback para registrar recompensas\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "import numpy as np\n",
    "\n",
    "class RewardLoggerCallback(BaseCallback):\n",
    "    def __init__(self, verbose=0):\n",
    "        super(RewardLoggerCallback, self).__init__(verbose)\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        if len(self.locals[\"infos\"]) > 0 and \"episode\" in self.locals[\"infos\"][0]:\n",
    "            episode_rewards = [info[\"episode\"][\"r\"] for info in self.locals[\"infos\"] if \"episode\" in info]\n",
    "            if episode_rewards:\n",
    "                mean_reward = np.mean(episode_rewards)\n",
    "                self.logger.record(\"reward/mean\", mean_reward)\n",
    "        return True\n",
    "\n",
    "from stable_baselines3.common.vec_env import SubprocVecEnv\n",
    "\n",
    "env = SubprocVecEnv([lambda: LunarLandingEnv() for _ in range(4)])\n",
    "# Criar o modelo\n",
    "model = PPO(\n",
    "    \"MlpPolicy\",\n",
    "    env,\n",
    "    verbose=1,\n",
    "    tensorboard_log=\"./ppo_lunar_landing_tensorboard/\",\n",
    "    learning_rate=3e-4,\n",
    "    n_steps=2048,\n",
    "    batch_size=64,\n",
    "    gae_lambda=0.95,\n",
    "    gamma=0.99,\n",
    "    ent_coef=0.0,\n",
    "    clip_range=0.2,\n",
    ")\n",
    "# Treinar o agente\n",
    "model.learn(total_timesteps=500_000, callback=RewardLoggerCallback())\n",
    "# Salvar o modelo\n",
    "model.save(\"ppo_lunar_landing\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Para ver o bot jogando:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "model = PPO.load(\"ppo_lunar_landing\")\n",
    "\n",
    "# Create a new environment for testing\n",
    "env = LunarLandingEnv()\n",
    "\n",
    "# Run the agent\n",
    "obs, _ = env.reset()\n",
    "done = False\n",
    "while not done:\n",
    "    action, _ = model.predict(obs)\n",
    "    obs, reward, done, _, _ = env.step(action)\n",
    "    env.render()\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Para jogar como humano (rode as próximas duas células):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def human_play():\n",
    "    import pygame\n",
    "    from pygame.locals import K_UP, K_LEFT, K_RIGHT, K_ESCAPE, QUIT\n",
    "\n",
    "    env = LunarLandingEnv()\n",
    "    env.reset()\n",
    "\n",
    "    # Inicializar Pygame\n",
    "    pygame.init()\n",
    "    screen = pygame.display.set_mode((env.screen_width, env.screen_height))\n",
    "    pygame.display.set_caption(\"Lunar Landing - Human Play\")\n",
    "    clock = pygame.time.Clock()\n",
    "\n",
    "    done = False\n",
    "    action = 0  # Ação inicial: Fazer nada\n",
    "\n",
    "    while not done:\n",
    "        for event in pygame.event.get():\n",
    "            if event.type == QUIT:\n",
    "                done = True\n",
    "            elif event.type == pygame.KEYDOWN:\n",
    "                if event.key == K_ESCAPE:  # Sair do jogo\n",
    "                    done = True\n",
    "                elif event.key == K_UP:  # Empuxo para cima\n",
    "                    action = 1\n",
    "                elif event.key == K_LEFT:  # Empuxo para esquerda\n",
    "                    action = 2\n",
    "                elif event.key == K_RIGHT:  # Empuxo para direita\n",
    "                    action = 3\n",
    "            elif event.type == pygame.KEYUP:\n",
    "                if event.key in [K_UP, K_LEFT, K_RIGHT]:  # Parar de aplicar força\n",
    "                    action = 0\n",
    "\n",
    "        # Atualizar o ambiente com a ação selecionada\n",
    "        obs, reward, terminated, truncated, info = env.step(action)\n",
    "\n",
    "        # Renderizar o ambiente\n",
    "        env.render()\n",
    "\n",
    "        # Verificar se o episódio terminou\n",
    "        if terminated or truncated:\n",
    "            print(\"Episódio terminou!\")\n",
    "            print(f\"Recompensa final: {reward}\")\n",
    "            break\n",
    "\n",
    "        # Limitar a taxa de quadros\n",
    "        clock.tick(env.metadata[\"render_fps\"])\n",
    "\n",
    "    # Fechar o ambiente\n",
    "    env.close()\n",
    "    pygame.quit()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episódio terminou!\n",
      "Recompensa final: -1.2500000000000366\n"
     ]
    }
   ],
   "source": [
    "human_play()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Para ver o bot jogando em 4 telas ao mesmo tempo (rode as próximas duas células):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "import numpy as np\n",
    "import pygame\n",
    "import random\n",
    "\n",
    "MAX_VEL_X = 5.0\n",
    "MAX_VEL_Y = 5.0\n",
    "\n",
    "class LunarLandingEnv(gym.Env):\n",
    "    metadata = {'render_modes': ['human'], 'render_fps': 60}\n",
    "\n",
    "    def __init__(self):\n",
    "        super(LunarLandingEnv, self).__init__()\n",
    "\n",
    "        # Define action and observation space\n",
    "        self.action_space = spaces.Discrete(4)\n",
    "\n",
    "        # Observations: x, y, velocity_x, velocity_y, fuel, landing_center_norm\n",
    "        low = np.array([-1, -1, -1, -1, 0, -1], dtype=np.float32)\n",
    "        high = np.array([1, 1, 1, 1, 1, 1], dtype=np.float32)\n",
    "        self.observation_space = spaces.Box(low, high, dtype=np.float32)\n",
    "\n",
    "        # Game parameters\n",
    "        self.gravity = 0.05\n",
    "        self.thrust_vertical = 0.1\n",
    "        self.thrust_horizontal = 0.05\n",
    "        self.max_fuel = 1000  # Increased fuel\n",
    "\n",
    "        # Screen dimensions\n",
    "        self.screen_width = 800\n",
    "        self.screen_height = 600\n",
    "        self.clock = None\n",
    "        self.is_open = True\n",
    "\n",
    "        # Game outcome\n",
    "        self.last_outcome = None  # Will be 'victory' or 'defeat' when the game ends\n",
    "\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        super().reset(seed=seed)\n",
    "        self.x = self.screen_width / 2  # Start at the center\n",
    "        self.y = 50\n",
    "        self.vel_x = 0.0\n",
    "        self.vel_y = 0.0\n",
    "        self.fuel = self.max_fuel\n",
    "        self.landing_zone = self._choose_landing_zone()\n",
    "        self.current_step = 0  # Step counter\n",
    "        self.max_steps = 1000  # Max steps per episode\n",
    "        self.last_outcome = None  # Reset outcome\n",
    "        return self._get_obs(), {}\n",
    "\n",
    "    def step(self, action):\n",
    "        # Apply action\n",
    "        if action == 1 and self.fuel > 0:  # Thrust Up\n",
    "            self.vel_y -= self.thrust_vertical\n",
    "            self.fuel -= 1\n",
    "        elif action == 2 and self.fuel > 0:  # Thrust Left\n",
    "            self.vel_x -= self.thrust_horizontal\n",
    "            self.fuel -= 1\n",
    "        elif action == 3 and self.fuel > 0:  # Thrust Right\n",
    "            self.vel_x += self.thrust_horizontal\n",
    "            self.fuel -= 1\n",
    "\n",
    "        # Update physics\n",
    "        self.vel_y += self.gravity\n",
    "        self.y += self.vel_y\n",
    "        self.x += self.vel_x\n",
    "\n",
    "        # Impose horizontal limits\n",
    "        self.x = max(20, min(self.x, 780))\n",
    "\n",
    "        # Increment step counter\n",
    "        self.current_step += 1\n",
    "\n",
    "        # Initialize reward and constants\n",
    "        reward = 0.0\n",
    "        k_y = 5  # Weight for vertical velocity adjustment\n",
    "        k_x = 4   # Weight for horizontal velocity adjustment\n",
    "        k_dir = 3  # Weight to penalize wrong direction\n",
    "        k_dist = 1  # Weight for distance from center\n",
    "\n",
    "        # Calculate landing zone center\n",
    "        landing_center = (self.landing_zone[0] + self.landing_zone[1]) / 2\n",
    "        distance_to_center_x = self.x - landing_center\n",
    "\n",
    "        # Reward for low and positive Y velocity\n",
    "        if 0.5 <= self.vel_y <= 1:\n",
    "            reward += k_y  # Max reward for ideal velocity\n",
    "        else:\n",
    "            reward -= k_y * abs(self.vel_y - 0.75)  # Penalty proportional to deviation from 0.75\n",
    "\n",
    "        if self.x < landing_center:  # Lander is to the left\n",
    "            if self.vel_x < 0.4:\n",
    "                if action == 3:  # Pushing to the right\n",
    "                    reward += k_x\n",
    "                elif action == 2:  # Pushing to the left\n",
    "                    reward -= k_dir\n",
    "\n",
    "        elif self.x > landing_center:  # Lander is to the right\n",
    "            if self.vel_x > -0.4:\n",
    "                if action == 2:  # Pushing to the left\n",
    "                    reward += k_x\n",
    "                elif action == 3:  # Pushing to the right\n",
    "                    reward -= k_dir\n",
    "\n",
    "        # Normalize reward between -10 and 10\n",
    "        reward = max(-10, min(10, reward))\n",
    "\n",
    "        # Check for termination\n",
    "        terminated = False\n",
    "        if self.y >= 530:  # Lander has reached the platform height\n",
    "            self.y = 530  # Adjust position to exactly on platform\n",
    "            # Determine if landing is successful\n",
    "            landing_velocity_threshold = 0.8  # units\n",
    "            if self.x > self.landing_zone[0] and self.x < self.landing_zone[1] and abs(self.vel_y) <= landing_velocity_threshold:\n",
    "                # Successful landing\n",
    "                self.last_outcome = 'victory'\n",
    "            else:\n",
    "                # Unsuccessful landing\n",
    "                self.last_outcome = 'defeat'\n",
    "            self.vel_y = 0  # Stop vertical movement\n",
    "            self.vel_x = 0  # Stop horizontal movement\n",
    "\n",
    "            terminated = True\n",
    "\n",
    "        elif self.current_step >= self.max_steps:\n",
    "            terminated = True\n",
    "            self.last_outcome = 'defeat'\n",
    "        elif self.y > self.screen_height or self.x <= 20 or self.x >= 780:\n",
    "            terminated = True\n",
    "            reward = -10  # Max penalty for going out of bounds\n",
    "            self.last_outcome = 'defeat'\n",
    "\n",
    "        # Return observations, reward, and episode info\n",
    "        return self._get_obs(), reward, terminated, False, {}\n",
    "\n",
    "    def render(self, surface):\n",
    "        if self.clock is None:\n",
    "            self.clock = pygame.time.Clock()\n",
    "\n",
    "        if self.last_outcome is None:\n",
    "            # Normal game rendering\n",
    "            surface.fill((0, 0, 0))  # Clear surface\n",
    "\n",
    "            # Draw game elements onto the surface\n",
    "            self._draw_stars(surface)\n",
    "            self._draw_terrain(surface)\n",
    "            self._draw_lander(surface)\n",
    "\n",
    "            # Show game state information\n",
    "            landing_center = (self.landing_zone[0] + self.landing_zone[1]) / 2\n",
    "            distance_to_center = self.x - landing_center\n",
    "\n",
    "            # Display rocket coordinates and state\n",
    "            font = pygame.font.Font(None, 36)\n",
    "            info_text = [\n",
    "                f\"Rocket X: {self.x:.2f}\",\n",
    "                f\"Rocket Y: {self.y:.2f}\",\n",
    "                f\"Distance to Center: {distance_to_center:.2f}\",\n",
    "                f\"Velocity X: {self.vel_x:.2f}\",\n",
    "                f\"Velocity Y: {self.vel_y:.2f}\",\n",
    "                f\"Fuel: {self.fuel}\",\n",
    "                f\"Landing Center X: {landing_center:.2f}\",\n",
    "            ]\n",
    "            for i, text in enumerate(info_text):\n",
    "                surface_text = font.render(text, True, (255, 255, 255))\n",
    "                surface.blit(surface_text, (10, 10 + i * 30))\n",
    "\n",
    "            # Visual marker for landing platform center\n",
    "            pygame.draw.circle(\n",
    "                surface, (0, 255, 0), (int(landing_center), 550), 5\n",
    "            )\n",
    "\n",
    "            # Display rocket's current coordinates next to it\n",
    "            coord_text = f\"({int(self.x)}, {int(self.y)})\"\n",
    "            coord_surface = font.render(coord_text, True, (255, 255, 255))\n",
    "            surface.blit(coord_surface, (int(self.x) + 20, int(self.y) - 40))\n",
    "\n",
    "        else:\n",
    "            # Draw victory or defeat screen\n",
    "            self._draw_end_screen(surface)\n",
    "\n",
    "    def _draw_end_screen(self, surface):\n",
    "        # Clear surface\n",
    "        surface.fill((0, 0, 0))\n",
    "\n",
    "        # Victory or defeat text\n",
    "        font = pygame.font.Font(None, 74)\n",
    "        if self.last_outcome == 'victory':\n",
    "            text = font.render(\"YOU WIN!\", True, (0, 255, 0))\n",
    "        else:\n",
    "            text = font.render(\"GAME OVER\", True, (255, 0, 0))\n",
    "        text_rect = text.get_rect(center=(self.screen_width // 2, self.screen_height // 2))\n",
    "        surface.blit(text, text_rect)\n",
    "\n",
    "    def close(self):\n",
    "        # No need to close any Pygame windows here\n",
    "        self.is_open = False\n",
    "\n",
    "    # Helper methods\n",
    "    def _choose_landing_zone(self):\n",
    "        start = random.randint(100, 600)\n",
    "        width = random.randint(50, 150)\n",
    "        end = start + width\n",
    "        return (start, end)\n",
    "\n",
    "    def _get_obs(self):\n",
    "        x_norm = (self.x - self.screen_width / 2) / (self.screen_width / 2)\n",
    "        y_norm = (self.y - self.screen_height / 2) / (self.screen_height / 2)\n",
    "        vel_x_norm = self.vel_x / MAX_VEL_X\n",
    "        vel_y_norm = self.vel_y / MAX_VEL_Y\n",
    "        fuel_norm = self.fuel / self.max_fuel\n",
    "        landing_center_norm = (self.landing_zone[0] + self.landing_zone[1]) / 2 / self.screen_width\n",
    "        return np.array(\n",
    "            [x_norm, y_norm, vel_x_norm, vel_y_norm, fuel_norm, landing_center_norm],\n",
    "            dtype=np.float32,\n",
    "        )\n",
    "\n",
    "    def _draw_stars(self, surface):\n",
    "        # Draw static stars onto the surface\n",
    "        if not hasattr(self, \"stars\"):\n",
    "            self.stars = [\n",
    "                (random.randint(0, self.screen_width), random.randint(0, self.screen_height)) for _ in range(50)\n",
    "            ]\n",
    "        for star in self.stars:\n",
    "            pygame.draw.circle(surface, (255, 255, 255), star, 2)\n",
    "\n",
    "    def _draw_terrain(self, surface):\n",
    "        # Draw terrain and landing zone onto the surface\n",
    "        pygame.draw.polygon(\n",
    "            surface,\n",
    "            (100, 100, 100),\n",
    "            [\n",
    "                (0, 550),\n",
    "                (200, 450),\n",
    "                (400, 500),\n",
    "                (600, 450),\n",
    "                (800, 550),\n",
    "                (800, 600),\n",
    "                (0, 600),\n",
    "            ],\n",
    "        )\n",
    "        # Draw landing zone\n",
    "        start, end = self.landing_zone\n",
    "        pygame.draw.rect(\n",
    "            surface, (150, 150, 150), (start, 550, end - start, 50)\n",
    "        )\n",
    "        # Flags\n",
    "        pygame.draw.line(surface, (255, 255, 255), (start, 550), (start, 520), 2)\n",
    "        pygame.draw.polygon(\n",
    "            surface,\n",
    "            (255, 255, 0),\n",
    "            [(start, 520), (start + 15, 527), (start, 534)],\n",
    "        )\n",
    "        pygame.draw.line(surface, (255, 255, 255), (end, 550), (end, 520), 2)\n",
    "        pygame.draw.polygon(\n",
    "            surface,\n",
    "            (255, 255, 0),\n",
    "            [(end, 520), (end - 15, 527), (end, 534)],\n",
    "        )\n",
    "\n",
    "    def _draw_lander(self, surface):\n",
    "        x = int(self.x)\n",
    "        y = int(self.y)\n",
    "\n",
    "        # Draw the lander onto the surface\n",
    "        pygame.draw.rect(\n",
    "            surface, (200, 200, 200), (x - 10, y - 30, 20, 60)\n",
    "        )  # Main body\n",
    "        pygame.draw.polygon(\n",
    "            surface,\n",
    "            (150, 150, 150),\n",
    "            [(x - 10, y + 20), (x - 20, y + 30), (x - 10, y + 30)],\n",
    "        )  # Left wing\n",
    "        pygame.draw.polygon(\n",
    "            surface,\n",
    "            (150, 150, 150),\n",
    "            [(x + 10, y + 20), (x + 20, y + 30), (x + 10, y + 30)],\n",
    "        )  # Right wing\n",
    "        pygame.draw.polygon(\n",
    "            surface,\n",
    "            (255, 0, 0),\n",
    "            [(x, y - 40), (x - 10, y - 30), (x + 10, y - 30)],\n",
    "        )  # Top cone\n",
    "\n",
    "        # Draw fuel level indicator\n",
    "        fuel_percentage = self.fuel / self.max_fuel\n",
    "        fuel_bar_height = 50\n",
    "        fuel_bar_width = 10\n",
    "        pygame.draw.rect(\n",
    "            surface,\n",
    "            (255, 255, 255),\n",
    "            (x - 25, y - 30, fuel_bar_width, fuel_bar_height),\n",
    "            1,\n",
    "        )  # Fuel bar border\n",
    "        pygame.draw.rect(\n",
    "            surface,\n",
    "            (0, 255, 0),\n",
    "            (\n",
    "                x - 25,\n",
    "                y - 30 + fuel_bar_height * (1 - fuel_percentage),\n",
    "                fuel_bar_width,\n",
    "                fuel_bar_height * fuel_percentage,\n",
    "            ),\n",
    "        )  # Fuel bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygame\n",
    "import numpy as np\n",
    "\n",
    "# Certifique-se de que o modelo PPO esteja carregado\n",
    "model = PPO.load(\"ppo_lunar_landing\")\n",
    "\n",
    "# Inicializar Pygame\n",
    "pygame.init()\n",
    "\n",
    "# Dimensões da tela\n",
    "SCREEN_WIDTH = 800\n",
    "SCREEN_HEIGHT = 600\n",
    "\n",
    "# Criar janela principal\n",
    "main_screen = pygame.display.set_mode((SCREEN_WIDTH, SCREEN_HEIGHT))\n",
    "pygame.display.set_caption(\"Lunar Lander - 4 Instâncias\")\n",
    "\n",
    "# Criar superfícies para cada ambiente\n",
    "surface_width = SCREEN_WIDTH\n",
    "surface_height = SCREEN_HEIGHT\n",
    "\n",
    "surfaces = [\n",
    "    pygame.Surface((surface_width, surface_height)),\n",
    "    pygame.Surface((surface_width, surface_height)),\n",
    "    pygame.Surface((surface_width, surface_height)),\n",
    "    pygame.Surface((surface_width, surface_height))\n",
    "]\n",
    "\n",
    "# Criar 4 ambientes\n",
    "envs = [LunarLandingEnv() for _ in range(4)]\n",
    "obs = [env.reset()[0] for env in envs]\n",
    "dones = [False for _ in range(4)]\n",
    "\n",
    "clock = pygame.time.Clock()\n",
    "running = True\n",
    "\n",
    "while running and not all(dones):\n",
    "    # Lidar com eventos\n",
    "    for event in pygame.event.get():\n",
    "        if event.type == pygame.QUIT:\n",
    "            running = False\n",
    "\n",
    "    # Atualizar e renderizar cada ambiente\n",
    "    for i in range(4):\n",
    "        if not dones[i]:\n",
    "            action, _ = model.predict(obs[i])\n",
    "            obs[i], reward, done, _, _ = envs[i].step(action)\n",
    "            dones[i] = done\n",
    "            # Renderizar o ambiente em sua superfície\n",
    "            envs[i].render(surfaces[i])\n",
    "\n",
    "    # Desenhar cada superfície na tela principal\n",
    "    # Superior esquerda\n",
    "    scaled_surface = pygame.transform.scale(surfaces[0], (SCREEN_WIDTH // 2, SCREEN_HEIGHT // 2))\n",
    "    main_screen.blit(scaled_surface, (0, 0))\n",
    "    # Superior direita\n",
    "    scaled_surface = pygame.transform.scale(surfaces[1], (SCREEN_WIDTH // 2, SCREEN_HEIGHT // 2))\n",
    "    main_screen.blit(scaled_surface, (SCREEN_WIDTH // 2, 0))\n",
    "    # Inferior esquerda\n",
    "    scaled_surface = pygame.transform.scale(surfaces[2], (SCREEN_WIDTH // 2, SCREEN_HEIGHT // 2))\n",
    "    main_screen.blit(scaled_surface, (0, SCREEN_HEIGHT // 2))\n",
    "    # Inferior direita\n",
    "    scaled_surface = pygame.transform.scale(surfaces[3], (SCREEN_WIDTH // 2, SCREEN_HEIGHT // 2))\n",
    "    main_screen.blit(scaled_surface, (SCREEN_WIDTH // 2, SCREEN_HEIGHT // 2))\n",
    "\n",
    "    # Atualizar a tela\n",
    "    pygame.display.flip()\n",
    "    clock.tick(60)  # Limitar a 60 FPS\n",
    "\n",
    "# Fechar ambientes\n",
    "for env in envs:\n",
    "    env.close()\n",
    "pygame.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
